{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvolutionBasedDeepNet-FashionMNIST.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chinmaysahu/Projects-Based-on-TensorFlow-for-Artificial-Intelligence-Machine-Learning-and-Deep-Learning/blob/master/ConvolutionBasedDeepNet_FashionMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "iQjHqsmTAVLU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fashion MNIST label Classification using Convolutions\n",
        "Here, we can improve MNIST classification to 99.8% accuracy or more using only a single convolutional layer and a single MaxPooling 2D. We use callbacks to stop training once the accuracy goes above this amount. It is achieved in less than 20 epochs, so it's ok to hard code the number of epochs for training, but our training ends once it hits the above metric.\n",
        "\n",
        "\n",
        "When 99.8% accuracy has been hit, we print out the string \"Reached 99.8% accuracy so cancelling training!\"\n"
      ]
    },
    {
      "metadata": {
        "id": "sfQRyaJWAIdg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "ca57af68-c2ab-4737-ab59-2ac5a5806b65"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.998):\n",
        "      print(\"\\nReached 99.8% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "callbacks = myCallback()\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=20, callbacks=[callbacks])\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 11s 186us/sample - loss: 0.1534 - acc: 0.9543\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 11s 183us/sample - loss: 0.0532 - acc: 0.9840\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 11s 183us/sample - loss: 0.0332 - acc: 0.9896\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 11s 184us/sample - loss: 0.0235 - acc: 0.9925\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 11s 183us/sample - loss: 0.0156 - acc: 0.9951\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 11s 183us/sample - loss: 0.0116 - acc: 0.9964\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 11s 183us/sample - loss: 0.0088 - acc: 0.9971\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 11s 183us/sample - loss: 0.0066 - acc: 0.9979\n",
            "Epoch 9/20\n",
            "59872/60000 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9982\n",
            "Reached 99.8% accuracy so cancelling training!\n",
            "60000/60000 [==============================] - 11s 183us/sample - loss: 0.0054 - acc: 0.9983\n",
            "10000/10000 [==============================] - 1s 84us/sample - loss: 0.0542 - acc: 0.9862\n",
            "0.9862\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}